---
layout: post
title:  "Minimax Magic"
date:   2018-08-06
excerpt: "The algorithm that beat the world Chess champion"
image: "/images/pic10.jpeg"
---

The MiniMax algorithm is often considered the holy grail of constructing AI for certain types of two-player games, and for good reason. Games like Tic-Tac-Toe, Checkers, Mancala and even Chess utilise this algorithm heavily in order to compose a competitive AI. The algorithm is also often used to "solve" these kind of two player games, in which an AI is developed that can "perfectly" play the game and reach a desired end state of either a draw or a victory, where if two AI perfectly play against each other, the game will inevitably result in a draw - I'll probably go into more detail on this in a later post.

Before actually delving into the algorithm, however, it is important to establish the preliminaries to implementing it. The algorithm is generally used in games that contain the "zero-sum" characteristic - this simply means that whenever one side gains an advantage, the other side is equally disadvantaged. A good example to demonstrate this, and an example I will be frequently using throughout this post, is the game of Chess. In Chess, if White captures a Black piece, then White gains an advantage equal to whatever number of points the captured piece is valued at. Similarly, however, Black is disadvantaged by a number of points equal to the piece that was taken from it.

Now in the zero-sum game of Chess, imagine if we declared every White piece has a value of 1, and every Black piece has a value of -1. Now if we were to evaluate the board to see which side is currently at an advantage, we could make use of a simplistic board evaluation function which simply totals up the values of **every** piece on the board to represent which side is currently winning. For example at the very start of a Chess game, obviously neither side is currently at an advantage; and using our system we can see the board evaluation function will hence return 0, indicating just this. However, if White were to capture a Black piece, then as there is one more White piece present on the board than Black pieces, we can see the function will return a value of +1. This positive value shows that White is currently in a position of advantage, and similarly if a negative value is returned we can see that Black is an advantageous position. And similar evaluation methods can be applied to every zero-sum two player game, in which an overall positive evaluation of the "board" (or whatever interface the game is played on) indicates a certain side is winning, and an overall negative evaluation indicates the other side is winning; although the evaluation function will clearly differ from each different type of game. But the important thing to remember is that it is possible, in any two-player zero-sum game, to compose an evaluation function that can indicate which side is winning by means of a positive or negative return value.

Now returning back to the example of Chess, let's make the evaluation function a bit more realistic by giving each piece a different value. Obviously a queen is worth more than a pawn, and thus accordingly we can give each piece a value corresponding to how important they are - let's say for this example that a pawn is worth 1 point, a knight/bishop is worth 3 points, a rook is worth 5 points, and a queen is worth 9 points. However, the actual win condition for Chess is based on capturing the King; and thus the value of the King should supposedly be placed at infinity, although for simplicity we'll just say that it is valued at 100 points. And of course, the Black pieces would retain the same value hierarchy but instead be negative to allow the evaluation function to distinguish which side is winning. So now that we have established this pointing system, if you were playing as White, what would you want to do? It's simple really - you would want to **maximise** the score returned by the board evaluation. After all, the higher the score, the more advantageous the position of White. And vice-versa for Black - you would want to **minimise** the score, as the lower the score, the more advantageous it is for Black. And this forms the very core of the MiniMax algorithm.

What the Mini-Max algorithm does is essentially scan through a tree of all the possible moves that can occur from the current state of the board (or whichever interface). The number of moves it looks into the future is dependent on the depth set on the call of the algorithm. A diagram will enable this to be explained much more efficiently:

<img src = "/images/pic10.JPG" width = "350" height = "250" />

In this diagram representing the MiniMax process for White selecting the most optimal move to play, the number of arrows sprawling out from each circle is the number of possible moves at a certain board state, and each circle itself is a certain board state. The circle right at the top represents the current board state, and as you can see in this board state White has only 2 valid moves to make. The algorithm then scans through these 2 moves and stores the 2 potential board states that arise from these, and then scans all the possible moves the other side can make - in this case Black. This is repeatedly done dependent on the depth value inserted when calling upon the algorithm, although in this case only a depth of 2 was selected, as the tree only contains the initial possible moves of White and the possible moves Black can respond to them. If the depth was set to 3, for example, the tree would then also contain the possible moves for White to respond to the moves Black can make, which themselves are in response to the initial possible moves of White, and so on. Now you will notice on the bottom layer the different board states that arise from the different possible moves of Black are all numbered - these are actually the values that arise from the evaluation function being ran on all these different board states. However, you'll notice none of the other circles have numbers in them, and thus the board states are only evaluated once the maximum depth has been reached, at what are called the **leaf nodes** - and this is a crucial part of the MiniMax algorithm. To be able to decide the optimal move only requires the leaf nodes to be evaluated and nothing else, which significantly improves performance in comparison to evaluating the board state of every single node. This is especially true of the more complex evaluation functions used in real-world Chess AIs, which take into account the very positions of the individual pieces and other factors such piece "mobility" that I won't go into here; but the point is that these functions are very demanding and thus the lower the number of times it is called, the more efficiently the AI will be run. 

From these leaf nodes, as it is the player wishing to minimise the score (as indicated in the diagram) which would be Black in the case of Chess, the algorithm automatically assumes that Black will choose the most optimal move which will result in the lowest score. So let us review the branches here: if White decides to take the move on the left, Black then has two possible moves it can make. One of its moves causes the board state to return a score of -5, and the other move causes the board state to return a score of 5. Now clearly the score of 5 is favourable to White, but we have to remember Black is playing here, and thus will seek to minimise the score. Thus the algorithm will assume Black will definitely choose the move that results in the board state returning a score of -5 - a score that is clearly shows Black is in an advantageous position. If, however, White chooses to make the move on the right, then Black can choose between two moves that results in a board evaluation of -2 or -1. In this case, Black will definitely choose to make the move that results in a score of -2. Therefore comparing these two results, we can see that White making the move on the right will clearly be the lesser of two evils, and thus the most optimal move to make. And all this is done through only evaluating the leaf nodes.

Naturally, however, in a real Chess game, or really any two-player zero-sum game (excluding possibly Tic-Tac-Toe), the move tree will be significantly larger than the example shown above. Thus a technique that can be applied to MiniMax to combat the sheer volume of the tree is a method called **alpha-beta pruning**, which is capable of removing entire branches to be searched, significantly improving performance.

To illustrate alpha-beta pruning I will use another tree diagram of the same depth to maintain simplicity, but also label the upper nodes with letters:

<span class="image left"><img src="{{ "/images/pic11.PNG" | absolute_url }}" alt="" /></span>

It is important to recognise here that A is the node that wishes to maximise the score, and B and C are nodes that wish to minimise the score. When alpha-beta pruning is implemented, the MiniMax function will now also take in 2 extra parameters - alpha and beta, where alpha is set to -infinity, and beta to infinity. Now when the algorithm is run, it will go to the first leaf node, which in this case gives a score of -5. As B here is trying to minimise the score, if the score is less than beta, which it is, then beta is set equal to the score, and thus is set to -5. The algorithm then proceeds to the next node, which is 4; thus beta retains its value at 4. However, now we go back to A, which is trying to maximise the score. Here, it checks if the score is greater than alpha - which it is - and thus sets the value to alpha. Now it goes down to C, which is trying to minimise the score, and checks the leaf node of score -7. However, at this stage it realises that -7 is less than alpha; and thus there is *no need* to evaluate the rest of the nodes branching from C, as any board state chosen from C will have a score equal or worse to -7, which is clearly worse for White than a score of -5. And thus in this way we can ignore evaluating the final leaf node. In much larger trees, it can be clearly seen that this can eliminate entire branches. 

I have recently coded a Chess AI which uses a MiniMax algorithm along with alpha-beta pruning, of which the source code can be found on my [GitHub](https://github.com/abhishekngen). The actual code of the algorithm involves a dual recursive function setup, although this can be simplified into one recursive function using what is known as the negamax variant; however, I won't go into this here. 